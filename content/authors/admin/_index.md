---
# Display name
title: Aayush Neupane

# Username (this should match the folder name and the name on publications)
authors:
  - "Aayush Neupane"

# Role/position
role: Grad Student, MSCS. Looking for Summer Internship 2026

# Short bio (displayed in user profile at end of posts)
bio: ""

# Remove the ones not needed
social:
  - icon: envelope
    icon_pack: fas
    link: "mailto:neupane0403@gmail.com"
  # - icon: google-scholar
  #   icon_pack: ai
  #   link: https://scholar.google.com/citations?user=1bEOmkUAAAAJ&hl=en
  # - icon: twitter
  #   icon_pack: fab
  #   link: https://twitter.com/alanlivio
  - icon: github
    icon_pack: fab
    link: https://github.com/atomnp
  - icon: linkedin
    icon_pack: fab
    link: "https://linkedin.com/in/aayushneupanee"
  # - icon : orcid
  #   icon_pack : ai
  #   link : 'https://orcid.org/0000-0003-0110-9975'
  # - icon : clarivate
  #   icon_pack : ai
  #   link : 'https://www.webofscience.com/wos/author/record/ABS-3947-2022'
  - icon: cv
    icon_pack: ai
    link: cv
# - icon: certificate
#   icon_pack: fas
#   link: certificates/

interests:
  - Software Engineering
  - Data Science and Machine Learning
  - Data Engineering
  - NLP, Programming languages, Software systems
# Organizational groups that you belong to (for People widget)
#   Set this to `[]` or comment out if you are not using People widget.
# user_groups:
#   - Researchers
---

I am a graduate student in Computer Science with a strong background in software, data, and machine learning engineering. Over the past few years, I have worked on projects that span from building large-scale data processing pipelines to deploying machine learning models in production environments. My work often sits at the intersection of software engineering and data science, designing reliable systems that can process, analyze, and learn from large and complex datasets.

At Smart Data Solutions, I engineered data pipelines integrating Java and Python components for processing scanned medical documents and applied NLP and deep learning models to automate information extraction. I have also worked on backend systems using Django, Celery, and Airflow, handling high-volume data storage and retrieval across SQL, NoSQL, and Redshift databases. Earlier, at Naamche, I contributed to full-stack and AI projects that combined LLMs, semantic search, and vector databases for real-time knowledge retrieval.

I am passionate about building scalable, data-driven systems that bridge the gap between infrastructure and intelligence. My interests include data engineering, distributed systems, and applied machine learning. I enjoy working in collaborative environments where I can contribute to both system design and model integration, continuously learning new tools and techniques to make data processing faster, smarter, and more reliable.